<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2024-10-29 Tue 13:56 -->
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>3-D Sensing</title>
<meta name="author" content="Matthew Elwin" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" href="./../pubme.css" type="text/css"/>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="../index.html"> UP </a>
 |
 <a accesskey="H" href="./../index.html"> HOME </a>
</div><div id="content" class="content">
<header>
<h1 class="title">3-D Sensing</h1>
</header><nav id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org6fd5f5f">Overview</a></li>
<li><a href="#org689b76e">Depth Image</a>
<ul>
<li><a href="#org2b9be6c">Structured Light</a></li>
<li><a href="#org2de20f0">Stereo Depth</a></li>
<li><a href="#orgee1053c">Time of Flight</a></li>
</ul>
</li>
<li><a href="#org57acf65">Point Clouds</a>
<ul>
<li><a href="#orgdec975b">Not Ported ROS 1 (yet)</a></li>
<li><a href="#orgc90956f">How To Point Cloud</a></li>
</ul>
</li>
<li><a href="#org767d74a">Devices that Generate Point Clouds</a></li>
<li><a href="#orgf47266b">Manipulating Point Clouds</a>
<ul>
<li><a href="#org2a7fea6">ROS</a></li>
<li><a href="#org6b69722">C++</a></li>
<li><a href="#orgc821e43">Python</a></li>
</ul>
</li>
<li><a href="#orge6f4de2">Resources</a></li>
</ul>
</div>
</nav>
<div id="outline-container-org6fd5f5f" class="outline-2">
<h2 id="org6fd5f5f">Overview</h2>
<div class="outline-text-2" id="text-org6fd5f5f">
<p>
There are many methods of providing 3-D sensor data to a robot, including ultrasound, sonar, radar, lidar, and stereo-vision.
Here we specifically focus on various light (lidar or vision) based sensing modalities.
</p>
</div>
</div>

<div id="outline-container-org689b76e" class="outline-2">
<h2 id="org689b76e">Depth Image</h2>
<div class="outline-text-2" id="text-org689b76e">
<p>
A depth image or depth map is a 2D dimensional image where each pixel value corresponds to the distance of an object from the camera.
There are several methods for generating a depth image.
</p>
</div>
<div id="outline-container-org2b9be6c" class="outline-3">
<h3 id="org2b9be6c">Structured Light</h3>
<div class="outline-text-3" id="text-org2b9be6c">
<ol class="org-ol">
<li>An active light emitter outputs a pattern</li>
<li>Objects deform the pattern</li>
<li>Image sensor senses the pattern and, using the distortion, computes the depth map</li>
<li>Good for indoors and short range, because they require seing the projected patterns.</li>
<li>Can be interfered with when, for example, there are multiple devices outputting patterns</li>
</ol>
</div>
</div>

<div id="outline-container-org2de20f0" class="outline-3">
<h3 id="org2de20f0">Stereo Depth</h3>
<div class="outline-text-3" id="text-org2de20f0">
<ol class="org-ol">
<li>Two images taken some known fixed distance apart</li>
<li>By comparing the images taken from known different angles, the depth can be known</li>
<li>The farther an object is from the sensors, the more similar the two images are</li>
<li>No active light emission is required so they do not interfere with each other.</li>
<li>Range is limited by distance between the two sensors.</li>
<li>Active IR can be used to create known features and enhance the accuracy</li>
</ol>
</div>
</div>
<div id="outline-container-orgee1053c" class="outline-3">
<h3 id="orgee1053c">Time of Flight</h3>
<div class="outline-text-3" id="text-orgee1053c">
<ul class="org-ul">
<li>LiDar</li>
<li>Measure depth by emitting light and timing how long it takes to reach the sensor</li>
<li>Very long range</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org57acf65" class="outline-2">
<h2 id="org57acf65">Point Clouds</h2>
<div class="outline-text-2" id="text-org57acf65">
<ul class="org-ul">
<li>A Point Cloud is a group of 3 dimensional coordinates (points) that
constitute a discrete description of 3-dimensional objects.</li>
<li>The <a href="https://pointclouds.org">point cloud library</a> contains routines for manipulating point clouds</li>
<li><a href="https://github.com/ros-perception/perception_pcl">perception_pcl</a> is a ROS meta-package for point clouds: install <code>ros-iron-perception-pcl</code></li>
</ul>
</div>


<details id="orgdec975b"><summary class="header-3">Not Ported ROS 1 (yet)</summary>
<div class="outline-text-3" id="text-orgdec975b">
<ul class="org-ul">
<li><a href="http://wiki.ros.org/pcl_ros/Tutorials">Point Cloud Tutorials</a></li>
<li><a href="https://github.com/ros-perception/perception_pcl/issues/225">pcl_ros</a> is a package that enabled a user to run a series of nodes performing specific point-cloud operations
<ul class="org-ul">
<li>It appears that it is installable on <code>iron</code> and parts of it work but parts of it definitely do not.</li>
</ul></li>
</ul>
</div>
</details>

<div id="outline-container-orgc90956f" class="outline-3">
<h3 id="orgc90956f">How To Point Cloud</h3>
<div class="outline-text-3" id="text-orgc90956f">
<ol class="org-ol">
<li>A depth map provides the distance from the camera in pixel coordinates</li>
<li>Using a camera calibration, this depth map is converted into real-world x,y,z coordinates</li>
<li>The pixels can be superimposed with data taken from an RGB camera to provide a 3D image</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org767d74a" class="outline-2">
<h2 id="org767d74a">Devices that Generate Point Clouds</h2>
<div class="outline-text-2" id="text-org767d74a">
<ul class="org-ul">
<li>Lidars/Laser Scanners 
<a href="http://wiki.ros/org/velodyne">Velodyne</a>
<a href="http://wiki.ros.node/urg_node">SCIP 2.2 laser range-finders</a></li>
<li>Stereo Cameras
<ul class="org-ul">
<li><a href="https://www.stereolabs.com/zed/">ZED 2</a></li>
<li><a href="https://www.flir.com/support/products/bumblebee2-firewire/?page=4#Overview">Bumblebee 2</a></li>
</ul></li>
<li>Depth Cameras
<ul class="org-ul">
<li><a href="./realsense.html">Intel RealSense</a></li>
<li><a href="http://wiki.ros.org/openni2_launch">opennni</a> (Like the Asus Xtion 2)</li>
<li>Kinect for Box 360 using <a href="http://wiki.ros.org/freenect_launch">freenect_launch</a></li>
<li>Kinect for Xbox One using <a href="https://github.com/code-iai/iai_kinect2">iai_kinect2</a></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgf47266b" class="outline-2">
<h2 id="orgf47266b">Manipulating Point Clouds</h2>
<div class="outline-text-2" id="text-orgf47266b">
<p>
There are several ways of manipulating point clouds in ROS. 
</p>
</div>
<div id="outline-container-org2a7fea6" class="outline-3">
<h3 id="org2a7fea6">ROS</h3>
<div class="outline-text-3" id="text-org2a7fea6">
<ul class="org-ul">
<li>In ROS, point clouds are sent using the <a href="https://github.com/ros2/common_interfaces/blob/iron/sensor_msgs/msg/PointCloud2.msg">sensor_msgs/msg/PointCloud2</a> messages
<ul class="org-ul">
<li>You can access the message fields directly but the format is not the most intuitive</li>
</ul></li>
<li>The <a href="http://wiki.ros.org/pcl_ros">pcl_ros</a> package (Not fully in ROS 2) is the primary ROS package for manipulating pointclouds
<ul class="org-ul">
<li>It includes several stand-alone filters that can be loaded as nodelets to perform common operations</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org6b69722" class="outline-3">
<h3 id="org6b69722">C++</h3>
<div class="outline-text-3" id="text-org6b69722">
<ul class="org-ul">
<li><a href="https://github.com/ros-perception/perception_pcl/tree/ros2/pcl_conversions">pcl_conversions</a> package also lets you convert point cloud messages into C++ data types for use with the <a href="https://pointclouds.org">Point Cloud Library</a>
<ul class="org-ul">
<li>While this is the most common way of handling point clouds in ROS, it is also a C++ only way</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgc821e43" class="outline-3">
<h3 id="orgc821e43">Python</h3>
<div class="outline-text-3" id="text-orgc821e43">
<ul class="org-ul">
<li>The <a href="https://index.ros.org/p/sensor_msgs_py/github-ros2-common_interfaces/#iron">sensor_msgs_py</a> package contains utilities for converting from PointCloud2 datatypes to numpy arrays</li>
<li><p>
For details:
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">from</span> sensor_msgs_py <span class="org-keyword">import</span> point_cloud2
<span class="org-builtin">help</span>(point_cloud2)
</pre>
</div></li>
<li>The <a href="https://github.com/strawlab/python-pcl">python-pcl</a> library lets you use the point cloud library from python (install with <code>apt install python-pcl</code>)</li>
<li>More details at <a href="https://pointclouds.org/">https://pointclouds.org/</a></li>
<li>An example project <a href="https://github.com/m-elwin/pointcloud_demo">https://github.com/m-elwin/pointcloud_demo</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orge6f4de2" class="outline-2">
<h2 id="orge6f4de2">Resources</h2>
<div class="outline-text-2" id="text-orge6f4de2">
<p>
<a href="https://www.intelrealsense.com/beginners-guide-to-depth/">Beginner's guide to depth</a>
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p><p class="outline-2">Author: Matthew Elwin. </p></p>
</div>
</body>
</html>
